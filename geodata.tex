\documentclass[12pt,a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage[colorlinks]{hyperref}
\usepackage[colorinlistoftodos]{todonotes}

\usepackage[numbers]{natbib}
\usepackage[nottoc]{tocbibind}

\usepackage{csquotes}

\usepackage{amssymb}

\usepackage{indentfirst}	% indent the first paragraph of a section

%
% Configure section/subsection etc printing and alignment
%
\usepackage{titlesec}

\titleformat{\section}[block] % shape
{\bfseries\large\centering} % format
{\thesection.}{16pt}{\large} % label
\titlespacing{\section}{12pc}{0cm}{1pc}

\titleformat{\subsection}[block]
{\normalfont\bfseries}
{\thesubsection.}{14pt}{}

\newcommand{\term}{\textit}
%\newcommand{\func}{\textsc}		% small capitals
\newcommand{\func}{\texttt}		% teletypefont family
\newcommand{\acr}{\MakeUppercase}
\newcommand{\eg}{\enquote}


\begin{document}
	\begin{titlepage}
		\begin{center}
			\thispagestyle{empty}
			\Large
			\textbf{Federated Geospatial Databases}
		\end{center}
	\end{titlepage}

	{
		\hypersetup{linkcolor=black}
		\tableofcontents
		\thispagestyle{empty}
		\newpage
	}
	
	\section{Introduction}
	\label{sec:intro}


	\todo[size={{\scriptsize}}]{Diversities in datasets! How to overcome this problem?}
	A \term{federated database} (also known as \term{integrated database} 
	\citep{Jian}) is a collection of cooperating database systems that are 
	autonomous and possibly heterogeneous \citep{Sheth}. The challenge in 
	federation arises from the heterogeneity of these autonomous databases (or 
	\term{archives} \citep{Malik}). Each  database  makes  independent choices 
	in its hardware, software, data schema, etc., and invests its resources 
	accordingly. As a result, differences arise among databases in the types of 
	network systems, operating systems, database systems, programming platforms, 
	and algorithmic techniques used. With the advance of more and more sensors 
	and automatic data acquisition tools, the number of available digital data 
	sets is ever increasing \citep{Butenuth}. This is especially true for 
	geospatial data, which are acquired by different organizations, e.g. 
	administrations like national mapping and environmental agencies, but also 
	private companies, e.g. in car navigation.
	\\

	\term{Geospatial data} is data about objects, events, or phenomena that have a location on the surface of the earth \citep{Stock}. The location may be 
	static in the short-term (e.g. the location of a road, an earthquake event, children living in poverty), or dynamic (e.g. a moving vehicle or pedestrian, even the spread of an infectious disease). Geospatial data combines location information (usually coordinates on the earth), attribute information (the characteristics of the object, event, or phenomena concerned), and often also temporal information (the time or life span at which the location and attributes exist). The terms geographical, spatial and geospatial are often used interchangeably. Subsequently, we will mostly use the term spatial interchangeably with geospatial.
	\\


	\citep{Butenuth}: Obviously, true integration is much more than just overlaying data in a geographic information system (GIS), as it must make the relations between the individual objects in the different data sets explicit. Technically, it also means more than information fusion, if the original data sets should still be available to be used in their own right. This is a common requirement today, as different agencies are interested in maintaining control over the data they are responsible for and they have the knowledge to maintain the data properly.
	\\


	\todo[size={{\scriptsize}}]{Keep fig. 4 ?}
	\citep{Butenuth}: (Given the structural adaptation of the different data sets, the federated database can be enabled to incorporate correspondences through so called links. ) In the context of federated databases the process of identifying objects is usually restricted to one-to-one correspondences often based on simple attribute matching (like, e.g. the ISBN of books). Identifying geospatial objects, however, does not only involve simple one-to-one-relationships, as real-world objects can be represented differently in different maps. Fig. 4 shows an instance of three and two objects, respectively, e.g. a section of a water body segmented in two different ways. To represent these many-to-many correspondences, the database stores attributed one-to-one links between aggregated objects (denoted by dashed lines in Fig. 4).
	\\


	The integration of heterogeneous geospatial data offers possibilities to manually and automatically derive new information, which are not available when using only a single data source \citep{Butenuth}. Furthermore, it allows for a consistent representation and the propagation of updates from one data set to the other. However, different acquisition methods, data schemata and updating cycles of the content can lead to discrepancies in geometric and thematic accuracy and correctness which hamper the combined integration. To overcome these difficulties, appropriate methods for the integration and harmonization of data from different sources and of different types are needed.
	\\

	The major challenge in building a federation of these autonomous and heterogeneous databases is system integration \citep{Malik}.
	\\



	\section{Federated Databases}
	\label{sec:fed}
	
	To the best of our knowledge the term \term{federated database system} was 
	introduced by \citet{Hammer}. They defined federated databases as a middle 
	road that should be followed between the rigid centralization of 
	conventional database systems and the anarchy of completely diffused and 
	decentralized files.
	\\

	Federated database systems have been extensively researched \citep{Sheth, Litwin}.
	Systems consisting of multiple database systems may be characterized along 
	three orthogonal dimensions: distribution, heterogeneity, and autonomy 
	\citep{Sheth}. 
	\begin{itemize}
		\item \term{Distribution}: Data may be distributed among multiple 
		databases. These databases may be stored on a single computer system or 
		on multiple computer systems. They can be co-located or geographically 
		distributed but interconnected by a communication system. Data may be 
		distributed among multiple databases in different ways. Multiple copies 
		of some or all of the data may be maintained. These copies need not be 
		identically structured.
		\item \term{Heterogeneity}: The types of heterogeneities in the 
		database systems can be divided into those due to the differences in 
		hardware or system software and those due to the differences in the 
		semantics of data. The differences in software refer to differences in 
		structure, constrains or query languages. Detecting semantic 
		heterogeneity is a much more difficult problem. It occurs when there is 
		a disagreement about the definition, interpretation, or intended use of 
		the same or related data (e.g. different precision of the data values). 
		\item \term{Autonomy}: Database systems are often under separate and 
		independent control. Those who control a autonomous database are often 
		willing to let others share the data only if they retain control. This 
		autonomy refers to design, communication and execution 
		\citep{Sheth, Heimbigner}. More concrete, each component database 
		system determines how it will view and combine existing data. It 
		decides when and how it responds to a request from another component. 
		And it must not be forced to perform an activity for another component. 
		Since the federation is a dynamic entity, components must be able to 
		dynamically enter or leave the federation. Consequently, heterogeneity 
		in an federated database system is primarily caused by design autonomy 
		among component database systems. 
	\end{itemize} 
	

	\todo[size={{\scriptsize}}]{??? See figure 2.}
	\citep{Jian}: A federated database can accept different heterogeneous systems and integrate them into higher level systems. They can be divided between two basic forms of interaction, cooperation and coordination. Cooperation means several systems or components use the same common data source. While in case of coordination, the desired data will be copied among these systems or components.
	\\

	\citep{Jian}: Some times users want to access data from various distinct databases. They used to create a new database and migrate all data from other databases to the new database. This is an approach of re-engineer databases. But the method has its obvious limitations.
	\\

	\citep{Butenuth}: Federated databases allow for integrating heterogeneous databases via a global schema, and they provide a unified database interface for global applications. Local applications remain unchanged, as they still access the databases via the local schemata.
	\\

	\citep{Malik}: An archive is naturally reluctant to forsake its autonomy – even if it is not, complete restructuring can be prohibitively expensive. Federated database architecture is designed to maintain autonomy and yet accomplish federated tasks.
	\\

	\citep{Butenuth}: Beside the general benefits of data integration, there are a lot of practical applications of integration. One is the verification and update of data sets: in order to check the currency and correctness of a data set, a second or third data set can be used to check the information. The task can be extended to provide also update capability: whenever current information is available in one data set, it can be employed to update the other sets, based on the known relations between the data sets and the known link structure between corresponding objects. Furthermore, integration can be used to provide prior information for a dedicated analysis using one data set: for example if a road network has to be updated using aerial imagery, information from existing road data can be used to partition the space and identify potential areas for new roads. Similarly, land use classifications from imagery can be used as input for a more detailed inspection of dedicated areas of interest. 
	\\



	\section{Geospatial Data}
	\label{sec:geo}

	\subsection{Theory}
	\label{sec:geo:th}

	\citet{Tomlinson} first coined the term \term{Geographic Information System 
	(\acr{gis})}, in order to store and manipulate map-based land data. However, 
	spatial analysis began in 1854 when cholera hit the city of London 
	\citep{whatIsGis}. British physician John Snow began mapping outbreak 
	locations to understand how the disease started.
	\\

	A \acr{gis} is a system designed to capture, store, manipulate, analyze, 
	manage, and visualize (usually in a map) all types of geographical data. 
	The key word to this technology is Geography – this means that some portion 
	of the data is geospatial. Interoperability of \acr{gis} is the ability to 
	access spatial data and associated services in a distributed and 
	heterogeneous processing environment \citep{Gong}. 
	\\

	\todo[size={{\scriptsize}}]{1. geospatial data join (vs relational database), 2. Hofmann}
	There were three methods to realize geospatial data sharing \citep{Shi}, 
	namely, through data exchange mode, database direct access mode or database 
	interoperability mode. 
	\begin{itemize} 
		\item \term{Data exchange mode} is not an optimal method. This data 
		sharing is based on files, which can be only used for data integration 
		but cannot realize real-time data sharing and data consistency. Each 
		update is only reflected in its own database. Thus, the interoperation 
		between two systems is not real interoperability. After data exchange, 
		information of the original data cannot be expressed accurately because 
		different data formats use different data models to describe the 
		spatial objects. That way information loss occurs.
		\item \term{Database direct access mode} allows users to obtain online 
		data by accessing multiple databases using different data formats. If 
		the data format of the host software changes, any software package for 
		data integration must re-address the changed format and then update 
		its own. But this is rarely announced when it happens, which makes it 
		difficult to access the changed format of the database for data 
		integration. As is obvious, direct access assumes sufficient 
		understanding of the data format and data model in the spatial database 
		at hand.
		\item \term{Database interoperability mode} is the database 
		interoperability that can be achieved based on one of \acr{com}, 
		\acr{corba} standards and the interface specification of \acr{sql}, or 
		based on Web Services. According to the first case, by constituting the 
		common interface function form and parameters, different \acr{gis} 
		software packages can directly access each other’s database. The second 
		case follows the specification of spatial data sharing models and 
		interoperation based on \acr{xml}.
	\end{itemize} 

	Below we will present a survey and analysis of geospatial joins.
	\\


	\subsection{Geospatial join basics}
	\label{sec:geo:join}

	Intuitively, given two datasets of multi-dimensional objects in Euclidean space, a spatial join finds all pairs of objects satisfying a given relation between the objects that involve the values of their spatial components, such as intersection \citep{Jacox}. For example, a spatial join answers such queries as \eg{find all of the rural areas that are below sea level}, given an elevation map and a land use map \citep{Veenhof}. To illustrate the concept further, a simplified version of a spatial join is as follows: given two sets of rectangles, $R$ and $S$, find all of the pairs of intersecting rectangles between the two sets. That is, for each rectangle $r$ in dataset $R$, find each intersecting rectangle $s$ from dataset $S$.
	\todo[size={{\scriptsize}}]{Maybe use an image to illustrate it? (e.g. like fig.1 from Jacox)}
	\\

	Spatial joins are distinguished from a standard relational join \citep{Mishra} in that the join condition involves the multi-dimensional spatial attribute of the joined relation. For instance, because the data objects are multi-dimensional, there is no ordering of the data that preserves proximity \citep{Mamoulis}. Relational join techniques that rely on sorting the data, such as the sort-merge join \citep{Mishra}, work because neighboring objects are adjacent to each other in the ordering. However, in more than one dimension, the data can not be sorted so that this property holds for all directions and dimensions.
	\\

	In general, processing spatial joins is more expensive than processing natural joins \citep{Brinkhoff96}. 
	\begin{itemize} 
		\item Spatial relations tend to contain more objects than an average-sized relation from a traditional application. In particular, this can be observed in those non-traditional geographic applications which strive for seamless spatial databases.
		\todo[size={{\scriptsize}}]{[Fra 91] from Brinkhoff 1996}
		\item The computation of the spatial join predicate, e.g. intersection of two polygonal objects, is considerably more expensive than the simple test on equality.
		\item A spatial object can be extremely large, i.e. it can consist of several hundred kilobytes. Therefore, the transfer time, i.e. the time to transfer spatial objects from secondary storage into main memory, considerably contributes to the total I/O cost. In contrast to large objects, the transfer time of small objects fitting in a data page can almost be ignored. In general, this is also fulfilled for natural join processing.
		\item Spatial join processing cannot exploit the technique of data declustering which is generally used as the basis for processing natural joins in parallel (partitioned parallelism \todo[size={{\scriptsize}}]{??? [Gra93] from Brinkhoff 1996}). Given a declustered data placement of spatial relations $R$ and $S$ into $p$ disjoint subsets $R_1,...,R_n$ and $S_1,...,S_n$, respectively, the union of the response sets obtained from processing spatial joins of $R_j$ and $S_j$, $1 \leq j \leq n$, is only a subset of the response set of the spatial join of $R$ and $S$.
	\end{itemize} 

	Typically, a spatial join is performed in two steps, according to the 
	\term{filter-and-refine approach} \citep{Orenstein89}. The \term{filter 
	step} during which all objects that could not possibly satisfy the query 
	are rapidly eliminated. The result of this step is a set of \term{candidate 
	objects} which includes all the objects satisfying the query, and possibly 
	some false hits. And then the subsequent \term{refinement step}, during 
	which each candidate is examined – false hits are detected and eliminated, 
	and the actual solutions are retrieved. In extreme cases, the filter step 
	would return the entire set of data objects, all of which would then have 
	to be considered by the refinement step.
	\par
	More concrete, during the filter step complicated polygonal objects are 
	approximated by rectangles, and the refinement stage removes any results 
	produced during the filtering stage that do not satisfy the join condition 
	\citep{Jacox}.
	\\ 

	In the filter-and-refine approach, the spatial join is first solved using approximations of the objects in the filtering stage. Any incorrect results due to the approximations are removed in the refinement stage using the full objects. In the filtering stage, objects are typically approximated using \term{minimum bounding 
	rectangles (\acr{mbr}s)}. An \acr{mbr} of an object is the smallest enclosing rectangle whose sides are parallel to the axes of the space. \acr{mbr}s require less storage space than the full object, resulting in faster processing and less expensive I/O operations \citep{Jacox}.
	\\


	\todo[size={{\scriptsize}}]{Orenstein86 ??}
	In addition to the processor speed and I/O performance, there are other factors that contribute to the performance of a spatial join \citep{Jacox}. The characteristics of the datasets and whether the datasets are indexed are also major influences on performance. The dataset sizes obviously effect overall performance, but a more important issue is whether the dataset fits into the available internal memory. If the entire dataset does fit in internal memory, then the spatial join can be done entirely in memory. This can be significantly faster than using external memory method.
	\par
	How the data is stored is another factor that contributes to the design of spatial joins. Vectors (a list of vertices) are commonly used to store polygons, but raster approaches are also used \citep{Orenstein86}. The choice of storage method for the full object mostly effects the complexity of the object intersection test during the refinement stage. During the filtering stage, an object is represented by an approximation (usually \acr{mbr}) and an object id, or by a pointer, in order to access the full object.
	\\


	During the filtering stage, a spatial join is performed on approximations of the objects. Let's now see how a spatial join is performed.
	\\



	\subsection{Technical}
	\label{sec:geo:tech}

	Let us start with techniques for performing a spatial join without using external memory. That is no data is written to external memory, only read once if necessary. 
	A line of research starts with \citet{Preparata} who introduced a computational geometry approach to solving the simplified spatial join (a two-set rectangle intersection), called \term{plane-sweep}. The algorithm has two passes. The first pass sorts the rectangles in ascending order on the basis of their left sides (i.e.,x coordinate values) and forms a list. The second pass sweeps a vertical scan line through the sorted list from left to right. When intersecting with a rectangle it halts, the rectangle becomes active, and is inserted into the set of active rectangles. Any rectangles entirely to the left of the scan line are removed from the set of active rectangles. To keep track of the active rectangles, the plane-sweep algorithm uses a \term{sweep structure} (for three dimensions see the \term{space-sweep} technique \citep{Preparata}).
	\par
	More concrete, to apply the plane-sweep algorithm, a sweep structure is needed for both $R$ and $S$ (see the simplified spatial join in Section~\ref{sec:geo:join}). Rectangles from $R$ are inserted into $R's$ sweep structure and rectangles from $S$ are inserted into $S's$ sweep structure. Then, each rectangle $r$ from $R$ will perform a search on $S's$ sweep structure, to find all the intersections with the rectangles in $S$, and vice versa. 
	\par
	A disadvantage of the plane-sweep algorithm is that its traditional version assumes that all of the data are in internal memory \citep{Jacox}. If the data is in external memory, then the entire dataset is first read into internal memory before performing the plane sweep. If the data is in external memory and sorted, then each object can be first read from external memory. Then inserted into the sweep structure. And finally purged from internal memory when it is deleted from the sweep structure. In this way, only the data intersecting the sweep line needs to be kept in internal memory. That has a two fold benefit. It reduces the internal memory requirements of the algorithm. And it increases the size of datasets that can be processed, without resorting to more sophisticated spatial join techniques.
	\\


A similar approach was proposed by \citet{Orenstein86} who used a variation of the Z-order method on spatial joins.
The z value of a region is a concise description of the shape, size and position of the region. 
Z values can be compared lexicographically, i.e. the bit strings are left-justified and then compared one bit at a time. Therefore a collection of elements can be ordered by sorting lexicographically on their z values.
The Z-order can ensure that larger objects will be seen first \citep{Jacox}. 
	\par
	For those who are not familiar with \term{Z-order}, it is a linear order 
	that creates a total order on multi-dimensional objects. The Z-order is a 
	traversal through a regular grid using a \eg{Z} pattern. It traverses the 
	grid in a pattern that helps to preserve locality. It first traverses 
	objects in a block before moving to the next block. If there are more than 
	four cells in the grid, then each top-level block is fully traversed before 
	moving to the next block. Linear orders that keep neighboring objects 
	closer in the order, on average, such as the Z-order, tend to be more 
	useful for spatial join algorithms.
	\par
\todo[size={{\scriptsize}}]{Does Orenstein86 combine z-order with plane-sweep? B-trees?}
The Z-order algorithm is nearly identical to the plane-sweep algorithm. First, the objects from both datasets are assigned to Z-order grid cells. Next, the objects are sorted in Z-order rather than one-dimensionally. In this case, the active set, instead of being the objects that intersect the sweep line, are the enclosing cells of the objects that intersect the current Z-order grid cell. Since a sufficiently fine grid cell will intersect fewer objects, the active set will be smaller and the sweep structure can be simpler.
\\



Even if there is sufficient internal memory to use one of the above internal memory techniques (plane-sweep and Z-order approach), if both datasets are indexed, then it can be faster to use the two-index filtering techniques\citep{Jacox}.
\par
\todo[size={{\scriptsize}}]{indexed dataset, 1 indexed 1 not, not-indexed datasets}
If neither dataset is indexed, then it might not be efficient to build indices in order to do a spatial join \citep{Jacox}. Especially if the indices will not be used again and immediately discarded, for example if the spatial join in question is an intermediate step in solving a complex query. Even so, at some point, most external memory spatial join algorithms reduce the size of the problem and process subsets of the data using internal memory techniques.
\\


Probably the most popular spatial access method is the R-tree \citep{Guttman}, when considering indexed datasets. An \term{R-tree} can be thought of as an extension of \term{B\textsuperscript{+}-tree} \citep{Comer} (see also \term{B-trees} \citep{Bayer}) in multi-dimensional space. There is no special ordering of objects in space that fully preserves spatial proximity \citep{Mamoulis}, so conventional indexes, such as B\textsuperscript{+}-trees, are inapplicable to spatial databases. R-trees index object approximations, usually \acr{mbr}s, providing a spatial join performed by a filter-and-refine approach.
\\





[[[[[[ The most basic spatial join method is the \term{nested-loop join}, which compares every object in one dataset to every object in the other dataset \citep{Mishra}. A variant of the nested-loop join algorithm, called the \term{index nested-loop join}, improves performance for larger datasets \citep{Jacox}. It first creates a spatial index and inserts every element of one dataset, say $A$ into this index. Next, the other dataset, say $B$ is scanned, and each element is used to search the index on dataset $A$ for intersections. Generally, the search window is a rectangle, which limits the types of join conditions to intersection tests or related relations that can be solved with a window query, such as proximity. ]]]]]]
\\


Let us consider two sets $A={a_1,...,a_n}$ and $B={b_1,...,b_m}$ of spatial objects, known as spatial relations \citep{Brinkhoff93}. The reader may think of the objects in a spatial relation as polygons representing a surface of a spatial object. Let \func{id} be a function that assigns a unique identifier to each spatial object in a database. Furthermore, let \func{mbr} be a function that computes the minimum bounding rectilinear rectangle of an object. For example, $\func{id}(a_1)$ and $\func{mbr}(a_1)$ denote the identifier and the minimum bounding rectangle of $a_1$, respectively. The most important spatial joins are the following:
\begin{itemize} 
	\item \acr{mbr}-spatial-join:\\ Compute all pairs $(\func{id}(a_i), \func{id}(b_j))$ with $\func{mbr}(a_i) \cap \func{mbr}(b_j) \neq \emptyset$\\
	\item \acr{id}-spatial-join:\\ Compute all pairs $(\func{id}(a_i), \func{id}(b_j))$ with $a_i \cap b_j \neq \emptyset$\\
	\item Object-spatial-join:\\ Compute $a_i \cap b_j$ with $a_i \cap b_j \neq \emptyset$
\end{itemize} 

The \acr{mbr}-spatial-join can be used for implementing the filter step of the \acr{id}-spatial-join and the object-spatial-join.
In addition to these three, there are also other types of joins – joins with other spatial operators than intersection, e.g. containment, or joins with more than two spatial relations.
\\






	\term{Multiway spatial joins} involve an arbitrary number of spatial inputs 
	\citep{Mamoulis}. Such queries are important in several applications 
	including \acr{gis} (e.g. find all cities adjacent to forests that are 
	intersected by a river).
	\\

	\citep{Mamoulis} : As in relational databases, joins in spatial databases play an important role in effective spatial query processing. A pairwise spatial join combines two datasets with respect to some spatial predicate (usually overlap). A typical example is “find all cities that are crossed by a river”. The most influential algorithm for joining two datasets indexed by R-trees is the R-tree join (RJ) \citep{Brinkhoff93} [the other? 1996?]. RJ traverses synchronously both trees, following entry pairs that overlap;non-intersecting pairs cannot lead to solutions at the lower levels. Most methods deal with the filter step; that is, they output a set of MBR pairs (candidates) that may enclose intersecting objects.
	\\

	

\citep{Jacox}: Unlike points, rectangles have extent, which complicates spatial join algorithms. 
\\
	

\todo[size={{\scriptsize}}]{plane-sweep algorithm? (Preparata et al.)}

	\citep{Brinkhoff96}: Another line of research starts with Orenstein and Manola [OM 88] who proposed to use B-trees combined with z-ordering for processing spatial joins. They followed the approach that for each object an approximation consists of a set of grid cells. A general problem with this approach is that a high number of cells per object is required to provide an accurate approximation of the object in order to obtain a small candidate set. This causes an expensive filter step.
	\\


	[[[[[[ \citep{Jacox}: it is assumed that the data is two dimensional and that we are interested in determining pairs of intersecting objects. Both of these assumptions are common in the literature. ]]]]]]



\citep{Orenstein86}: support spatial query processing by providing an object class that implements approximate geometry (AG). Approximate geometry, as developed here, relies (conceptually) on a grid representation of spatial data. This is where the approximation comes in - precision is limited by the resolution of the grid. The AG algorithms are exact. I.e., if the grid representation is considered to be precise (as might be the case for LANDSAT data), then AG would provide precise results. Common techniques for file organization (e.g. B-trees) and buffer management provide excellent support for AG. [[[We are not aware of any other approach to spatial data that can make this claim.]]]
\\


\citep{Orenstein86}: Their approach to approximate grid (AG) is based on a grid representation of spatial objects. [[[Implementations of spatial join that incorporate the optimizations discussed above will be designed in the next phase of PROBE research.]]]
\\
\citep{Orenstein89}: An algorithm called spatial join implements the filter step. Each resulting candidate is a pair of objects, one from each input file. that are likely to overlap. The output from spatial join has to go through a refinement step as described above. Spatial join and filtering algorithms for other spatial problems appear in [OREN88]. These algorithms comprise the geometry filter (GF).
\\

\citep{Orenstein86}: The z value of a region is a concise description of the shape, size and position of the region. These can be derived from the z value. 
Z ordering is a total ordering of elements. This property, combined with the highly constrained splitting policy that produces elements, leads to the following observation. The only possible relationships between elements are containment and precedence (in z order). Overlap (other than containment) cannot occur. This leads to very simple algorithms based on the merging of sequences of elements. Much of the usefulness of z order IS based on the property that it preserves proximity, i.e. if two points are close in space then they are likely to be close in z order. 
\par
\citep{Orenstein84}: By interleaving the bits of the binary representations of the attribute valued in a tuple, an integer corresponding to the tuple is created. A set of these integers represents a relation. The usual ordering of these integers (z ordering?????) corresponds to an ordering of multi-dimensional data that allows the use of conventional file organizations, such as B-trees, in the efficient processing of multi-dimensional queries (e.g. range queries).
\\

\citep{Orenstein89}: The spatial join algorithm performs a merge of two geometry filter (GF) sequences, searching for situations where an element in one sequence, as represented by its z value, contains an element from the other input. (This can be determined by checking whether one z value is a prefix of the other.) When such a pair is found, a candidate, comprising the objects associated with the elements, is generated. 
\\




	\citet{Jacox} comprehensive survey on spatial data joins.
	\\

	A typical spatial join technique consists of the following components: partitioning the data, performing internal memory spatial joins on subsets of the data, and checking if the full polygons intersect \citep{Jacox}.
	\\


	There exist several methods for performing a spatial join on R-trees \citep{Guttman}.
	\\

	Applications such as \acr{gis} require the ability to deal with data objects other than points and query objects other than boxes \citep{Orenstein89}. This motivates 
	consideration of the overlap query. The \term{overlap query} takes as input 
	two sets of spatial objects, R and S. And returns a set of pairs (r, s) 
	such that r is a member of R and s is a member of S – r and s overlap 
	spatially. The \term{range query} is a special case of the overlap query in 
	which one set contains points and the other set contains a single box.
	\\
	OR
	\\
	A spatial database system must be able to store spatial objects and efficiently retrieve those objects in response to queries involving spatial predicates such as overlap, containment and proximity. Many useful queries are special cases of the overlap query. The \term{overlap query} takes as input two sets of spatial objects, R and S. And returns a set of pairs (r, s) 
	such that r is a member of R and s is a member of S – r and s overlap spatially. Many queries involving spatial predicates can be easily mapped into overlap queries. The \term{range query} is a special case of the overlap query in which one set contains data points, and the other set contains a single query box.
	\\

	


 	Each spatial object in each input set is transformed to a set of 1-d intervals. An algorithm called spatial join implements the filter step. Each resulting candidate is a pair of objects, one from each input set, that are likely to overlap. The output from spatial join has to go through a refinement step as described above. These algorithms comprise the geometry filter \citep{Orenstein89}.
 	\\


	Notes \citep{Jacox}:
	1) The computational geometry approach to solving the simplified spatial join (a two-set rectangle intersection) is to use a plane-sweep technique [Preparata and Shamos 1985].

	2) Vectors (a list of vertices) are commonly used to store polygons, but raster approaches are also used [Orenstein 1986].

	Noter \citep{Brinkhoff93}:
	1) Orenstein (1986)[18] has proposed B+-trees in combination with z-ordering as the underlying access method for performing spatial joins.
	\\






	\section{Federated Geospatial Databases}
	\label{sec:fed_geo}

	\citet{Butenuth} developed a mechanism for the semantic description of 
	geospatial objects, in order to provide the applications with a model 
	independent and uniform method to access objects with respect to thematic 
	attributes. In order to perform the integration of various types of 
	geospatial data they describe two integration algorithms. The one is for 
	matching and aligning heterogeneous vector data sets and a second one for 
	integrating raster and vector data. Both algorithms are linked to a 
	federated database as a base for any kind of complex data handling (it 
	allows for automatic object matching and for managing n:m relationships).
	\par
	Vector and raster data are the two primary types of spatial data in 
	\acr{gis} \citep{vectorVSraster}. The three basic symbol types for vector 
	data are points (e.g. cities in maps), lines (e.g. rivers or roads in maps) 
	and polygons (e.g. building footprints, agricultural fields). Polygon 
	features are most commonly distinguished using either a thematic mapping 
	symbology (color schemes), patterns, or in the case of numeric gradation, 
	a color gradation scheme \citep{Dempsey}.
	\par 
	On the other hand raster data is made up of pixels (also referred to as 
	grid cells). They are useful for storing data representing surfaces, that 
	either vary continuously or are discrete. An example of discrete raster 
	data is population density. Continuous data examples are temperature,
	elevation measurements and lead contamination. Unlike vector data, raster 
	data is formed by each cell receiving the value of the feature that 
	dominates the cell. Rasters are digital aerial photographs, imagery from 
	satellites \citep{Butenuth}, digital pictures, scanned maps and so on.
	\par
	Most \acr{gis} software applications mainly focus on the usage and 
	manipulation of vector geospatial databases with added components to work 
	with raster-based geospatial databases \citep{Dempsey}.
	\\

	\citet{Jian} introduced a method based on \acr{opengis} 
	\footnote{ \url{https://www.opengeospatial.org/}} and \acr{com} 
	\footnote{ \url{https://docs.microsoft.com/en-us/windows/win32/com/com-technical-overview}} 
	that integrates three databases, a vector database, a 
	\term{digital elevation model (\acr{dem})} database and an image database. 
	A \acr{dem} is a 3D representation of a terrain's surface – commonly of a 
	planet, moon, or asteroid – created from a terrain's elevation data. 
	\term{Open Geodata Interoperability Specification (\acr{opengis})} 
	provides a framework to create software that enables users to access and 
	process geographic data from a variety of sources across a generic computing 
	interface And \term{Component Object Model (\acr{com})} is a software 
	architecture that allows the components that made by different software 
	vendors to be combined into an integrated application. 
	\\

	\citet{Malik} presented \term{SkyQuery}, a prototype federation of 
	geographically separate astronomy databases. SkyQuery supports a federated 
	query called the \term{cross match query}. This is a spatial join query 
	that matches objects between databases, if they correspond to the same 
	astronomical body. Through these queries, the users are able to observe the 
	same sky in other wavelengths (using someone else’s data) and combine the 
	available observations into a multi-spectral data set. This immensely aids 
	in making discoveries faster and easier.
	\\

	There is not much work done on the merging of federated systems and geospatial databases.
	Interoperability among traditional geographical information systems requires solving two major problems \citep{Gong}. The former is how to access geospatial data distributed on the network. And the latter is how to allow cooperation between existing heterogeneous geospatial databases.
	\par
	The first problem is dealt with by using networking techniques based on the client/server paradigm. For example a distributed object environment, like CORBA can be used to provide interconnectivity among several geographical information systems.
	\par
	The second problem has recently been the focus of extensive researches in the field of databases. Several solutions have been identified: Schema integration based solutions aim to combine all information into a single global schema. Canonical data-model based solutions hide heterogeneity and provide a good framework for multi-model translations. Multi-database language based solutions allow users to query several information sources at the same time.
	\\ 

	\citep{Gong}: In order to solve problems, we often need the cooperation of many spatial databases, even if there are more complex spatial relationship and diversity between the existing spatial data models.
	\\



	\newpage
	\renewcommand{\bibname}{References}
	\bibliography{ref}
	\bibliographystyle{unsrtnat}
\end{document}
\grid
\grid
